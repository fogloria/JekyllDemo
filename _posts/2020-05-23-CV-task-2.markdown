---
layout: post
title:  "å…¥é—¨CV - task2 æ•°æ®è¯»å–ä¸æ‰©å¢"
date:   2020-05-23 22:00:24 +0800
categories: CV
---
## Pytorchå¦‚ä½•è¯»å–æ•°æ®ï¼Ÿ

Pythonè¯»å–æ•°æ®çš„åº“æœ‰ï¼šPillowï¼ŒOpenCV

é—®ï¼šè¿™ä¸¤ä¸ªåº“åœ¨è¯»å–å›¾åƒçš„æ—¶å€™å·²ç»æ˜¯åœ¨åšæ•°æ®æ‰©å¢äº†å—ï¼Ÿ



### Pillowï¼ˆå›¾åƒå¤„ç†å‡½å¼åº“PILçš„ä¸€ä¸ªåˆ†æ”¯ï¼‰

```python
from PIL import image
im=Image.open('cat.jpg')
# åº”ç”¨æ¨¡ç³Šæ»¤é•œ
im2=im.filter(ImageFilter.BLUR)
im2.save('blur.jpg','jpeg')
# æ”¹å˜å›¾åƒå®½é«˜
im3=im.thumbnail((w//2,h//2))
im3=im.save('thumbnail.jpg','jpeg')
```

æ›´å¤šï¼š[Pillowå®˜æ–¹æ–‡æ¡£](https://pillow.readthedocs.io/en/stable/)



### OpenCV

```python
import cv2
img=cv2.imread('cat.jpg')
img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB) # OpenCVé»˜è®¤é¢œè‰²é€šé“é¡ºåºæ˜¯BGRï¼Œå¾—è½¬æ¢ä¸‹
img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # è½¬ä¸ºç°åº¦å›¾
edges=cv2.Canny(img,30,70)
cv2.imwrite('canny.jpg',edges) # Cannyè¾¹ç¼˜æ£€æµ‹
```

è¿˜æœ‰è¶…å¤šå›¾åƒç‰¹å¾å¤„ç†ç®—æ³•ï¼Œå¦‚å…³é”®ç‚¹æ£€æµ‹ã€ç›´çº¿æ£€æµ‹ç­‰ï¼Œè§[å®˜ç½‘](https://opencv.org/)



## ä¸ºä»€ä¹ˆè¦å¯¹æ•°æ®è¿›è¡Œæ‰©å¢ï¼Ÿ

å¢åŠ æ ·æœ¬é‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå¢å¼ºæ¨¡å‹çš„**æ³›åŒ–**èƒ½åŠ›

å‡è®¾ç°åœ¨çš„åˆ†ç±»æ¨¡å‹éœ€è¦å¯¹æ±½è½¦è¿›è¡Œåˆ†ç±»ï¼Œå·¦è¾¹çš„æ˜¯æ±½è½¦Aï¼Œå³è¾¹ä¸ºæ±½è½¦Bã€‚å¦‚æœä¸ä½¿ç”¨ä»»ä½•æ•°æ®æ‰©å¢æ–¹æ³•ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹ä¼šä»æ±½è½¦è½¦å¤´çš„è§’åº¦æ¥è¿›è¡Œåˆ¤åˆ«ï¼Œè€Œä¸æ˜¯æ±½è½¦å…·ä½“çš„åŒºåˆ«ã€‚

[![IMG](https://github.com/datawhalechina/team-learning/raw/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/IMG/Task02/%E6%95%B0%E6%8D%AE%E6%89%A9%E5%A2%9Ecar.png)](https://github.com/datawhalechina/team-learning/blob/master/03 è®¡ç®—æœºè§†è§‰/è®¡ç®—æœºè§†è§‰å®è·µï¼ˆè¡—æ™¯å­—ç¬¦ç¼–ç è¯†åˆ«ï¼‰/IMG/Task02/æ•°æ®æ‰©å¢car.png)



### æ•°æ®æ‰©å¢æ–¹æ³•

é¢œè‰²ã€å°ºåº¦ã€æ ·æœ¬ç­‰ï¼Œæ ¹æ®ä¸åŒä»»åŠ¡æ‰©å¢æ–¹æ³•æœ‰åŒºåˆ«ï¼Œå¦‚æœ¬é¢˜æ˜¯è¯†åˆ«æ•°å­—æ ‡ç­¾ï¼Œç¿»è½¬ä¸å¯ä»¥ğŸ™…ï¼ˆ6ä¼šå˜æˆ9ï¼‰

ä»¥torchvisionä¸ºä¾‹ï¼Œæœ‰å¦‚ä¸‹æ‰©å¢æ–¹æ³•ï¼š

>- transforms.CenterCrop å¯¹å›¾ç‰‡ä¸­å¿ƒè¿›è¡Œè£å‰ª
>- transforms.ColorJitter å¯¹å›¾åƒé¢œè‰²çš„å¯¹æ¯”åº¦ã€é¥±å’Œåº¦å’Œé›¶åº¦è¿›è¡Œå˜æ¢
>- transforms.FiveCrop å¯¹å›¾åƒå››ä¸ªè§’å’Œä¸­å¿ƒè¿›è¡Œè£å‰ªå¾—åˆ°äº”åˆ†å›¾åƒ
>- transforms.Grayscale å¯¹å›¾åƒè¿›è¡Œç°åº¦å˜æ¢
>- transforms.Pad ä½¿ç”¨å›ºå®šå€¼è¿›è¡Œåƒç´ å¡«å……
>- transforms.RandomAffine éšæœºä»¿å°„å˜æ¢
>- transforms.RandomCrop éšæœºåŒºåŸŸè£å‰ª
>- transforms.RandomHorizontalFlip éšæœºæ°´å¹³ç¿»è½¬
>- transforms.RandomRotation éšæœºæ—‹è½¬
>- transforms.RandomVerticalFlip éšæœºå‚ç›´ç¿»è½¬



### æ•°æ®æ‰©å¢åº“

[torchvision](https://github.com/pytorch/vision) : ä¸torchæ— ç¼é›†æˆï¼Œæ–¹æ³•å°‘ï¼Œé€Ÿåº¦ä¸€èˆ¬

[imgaug](https://github.com/aleju/imgaug) : æ–¹æ³•å¤šæ ·ï¼Œç»„åˆæ–¹ä¾¿ï¼Œé€Ÿåº¦å¿« 

[albumentations]([https://albumentations.readthedocs.io](https://albumentations.readthedocs.io/)) : æ”¯æŒè¯­ä¹‰åˆ†å‰²ã€ç‰©ä½“æ£€æµ‹ã€å…³é”®ç‚¹æ£€æµ‹ç­‰ï¼Œé€Ÿåº¦å¿« 



## Pytorchè¯»å–æ•°æ®

åœ¨Pytorchä¸­æ•°æ®æ˜¯é€šè¿‡Datasetè¿›è¡Œå°è£…ï¼Œå¹¶é€šè¿‡DataLoaderè¿›è¡Œ**å¹¶è¡Œè¯»å–**

```python
import os, sys, glob, shutil, json
import cv2

from PIL import Image
import numpy as np

import torch
from torch.utils.data.dataset import Dataset
import torchvision.transforms as transforms

class SVHNDataset(Dataset):
    def __init__(self, img_path, img_label, transform=None):
        self.img_path = img_path
        self.img_label = img_label 
        if transform is not None:
            self.transform = transform
        else:
            self.transform = None

    def __getitem__(self, index):
        img = Image.open(self.img_path[index]).convert('RGB')

        if self.transform is not None:
            img = self.transform(img)
        
        # åŸå§‹SVHNä¸­ç±»åˆ«10ä¸ºæ•°å­—0
        lbl = np.array(self.img_label[index], dtype=np.int)
        lbl = list(lbl)  + (5 - len(lbl)) * [10]
        
        return img, torch.from_numpy(np.array(lbl[:5]))

    def __len__(self):
        return len(self.img_path)

train_path = glob.glob('../input/train/*.png')
train_path.sort()
train_json = json.load(open('../input/train.json'))
train_label = [train_json[x]['label'] for x in train_json]

data = SVHNDataset(train_path, train_label,
          transforms.Compose([
              transforms.Resize((64, 128)),# ç¼©æ”¾åˆ°å›ºå®šå°ºå¯¸
              transforms.ColorJitter(0.2, 0.2, 0.2),# éšæœºé¢œè‰²å˜æ¢
              transforms.RandomRotation(5),# åŠ å…¥éšæœºæ—‹è½¬

              # å°†å›¾ç‰‡è½¬æ¢ä¸ºpytorch çš„tesntor
              # transforms.ToTensor(),

              # å¯¹å›¾åƒåƒç´ è¿›è¡Œå½’ä¸€åŒ–
              # transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
            ]))
```



### Dataset ä¸ DataLoader

- Datasetï¼šå¯¹æ•°æ®é›†çš„å°è£…ï¼Œæä¾›ç´¢å¼•æ–¹å¼çš„å¯¹æ•°æ®æ ·æœ¬è¿›è¡Œè¯»å–
- DataLoaderï¼šå¯¹Datasetè¿›è¡Œå°è£…ï¼Œæä¾›æ‰¹é‡è¯»å–çš„è¿­ä»£è¯»å–

```python
import os, sys, glob, shutil, json
import cv2

from PIL import Image
import numpy as np

import torch
from torch.utils.data.dataset import Dataset
import torchvision.transforms as transforms

class SVHNDataset(Dataset):
    def __init__(self, img_path, img_label, transform=None):
        self.img_path = img_path
        self.img_label = img_label 
        if transform is not None:
            self.transform = transform
        else:
            self.transform = None

    def __getitem__(self, index):
        img = Image.open(self.img_path[index]).convert('RGB')

        if self.transform is not None:
            img = self.transform(img)
        
        # åŸå§‹SVHNä¸­ç±»åˆ«10ä¸ºæ•°å­—0
        lbl = np.array(self.img_label[index], dtype=np.int)
        lbl = list(lbl)  + (5 - len(lbl)) * [10]
        
        return img, torch.from_numpy(np.array(lbl[:5]))

    def __len__(self):
        return len(self.img_path)

train_path = glob.glob('../input/train/*.png')
train_path.sort()
train_json = json.load(open('../input/train.json'))
train_label = [train_json[x]['label'] for x in train_json]

train_loader = torch.utils.data.DataLoader(
        SVHNDataset(train_path, train_label,
                   transforms.Compose([
                       transforms.Resize((64, 128)),
                       transforms.ColorJitter(0.3, 0.3, 0.2),
                       transforms.RandomRotation(5),
                       transforms.ToTensor(),
                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])), 
    batch_size=10, # æ¯æ‰¹æ ·æœ¬ä¸ªæ•°
    shuffle=False, # æ˜¯å¦æ‰“ä¹±é¡ºåº
    num_workers=10, # è¯»å–çš„çº¿ç¨‹ä¸ªæ•°
)

for data in train_loader:
    break
```

åœ¨åŠ å…¥DataLoaderåï¼Œæ•°æ®æŒ‰ç…§æ‰¹æ¬¡è·å–ï¼Œæ¯æ‰¹æ¬¡è°ƒç”¨Datasetè¯»å–å•ä¸ªæ ·æœ¬è¿›è¡Œæ‹¼æ¥ã€‚æ­¤æ—¶dataçš„æ ¼å¼ä¸ºï¼š
`torch.Size([10, 3, 64, 128]), torch.Size([10, 6])`
å‰è€…ä¸ºå›¾åƒæ–‡ä»¶ï¼Œä¸ºbatchsize * channel * height * widthæ¬¡åºï¼›åè€…ä¸ºå­—ç¬¦æ ‡ç­¾ã€‚



é—®ï¼š\_\_getitem \_\_éƒ¨åˆ†çš„ä»£ç çœ‹ä¸æ‡‚



