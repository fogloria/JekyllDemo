---
layout: post
title:  "入门CV - task4 训练与验证"
date:   2020-05-29 15:30:00 +0800
categories: CV
---
## 合格的深度学习训练流程是怎样的？

- 在训练集上进行训练，并在验证集上进行验证；
- 模型可以保存最优的权重，并读取权重；
- 记录下训练集和验证集的精度，便于调参。

***过拟合***最常见的原因是**模型复杂度**（Model Complexity）**太高**，模型学习了训练数据的细枝末节的规律，此时需要构建与测试集尽可能分布一致的**验证集**，在训练过程中不断验证模型在验证集上的精度，以控制模型的训练。

- #### 训练集（Train Set）：模型用于训练和调整模型参数；

- #### 验证集（Validation Set）：用来验证模型精度和调整模型超参数；

- #### 测试集（Test Set）：验证模型的泛化能力。



## 如何划分本地验证集？

从训练集中拆分

[![IMG](https://github.com/datawhalechina/team-learning/raw/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/IMG/Task04/%E9%AA%8C%E8%AF%81%E9%9B%86%E6%9E%84%E9%80%A0.png)](https://github.com/datawhalechina/team-learning/blob/master/03 计算机视觉/计算机视觉实践（街景字符编码识别）/IMG/Task04/验证集构造.png)



>**留出法：**训练集划分为2份，新的训练集和验证集。可能导致模型在验证集上过拟合，适合较大的数据量。
>
>**交叉验证法：**将训练集划分成K份，将K-1份作为训练集，剩余1份作为验证集，循环K训练。那么所有的训练集都将是验证集，最终验证精度是K份平均得到的。优点：训练K次可得到K个有多样性差异的模型；缺点：不适合大数据量。
>
>**自助采样法**：**有放回**的采样方式，每次训练集和验证集都是有区别的。适合小数据量。



*任何的验证集的划分得到的验证集都是要保证训练集-验证集-测试集的**分布是一致的**，所以如果不管划分何种的划分方式都是需要注意的。

这里的分布一般指的是**与标签相关的统计分布**，比如在分类任务中“分布”指的是标签的类别分布，训练集-验证集-测试集的类别分布情况应该大体一致；**如果标签是带有时序信息，则验证集和测试集的时间间隔应该保持一致。**



## 代码

每轮进行训练和验证，并根据最优验证集精度保存模型。

```python
train_loader=torch.utils.data.DataLoader(
  train_dataset,
  batch_size=10,
  shuffle=True,
  num_workers=10,
)

val_loader=torch.utils.data.DataLoader(
  val_dataset,
  batch_size=10,
  shuffle=False,
  num_workers=10,
)

model=SVHN_Model1()
criterion=nn.CrossEntropyLoss(size_average=False)
optimizer=torch.optim.Adam(model.parameters(),0.001)
best_loss=1000.0  #????什么意思
for epoch in range(20):
  print('Epoch:',epoch)
  
  train(train_loader,model,criterion,optimizer,epoch)
  val_loss=validate(val_loader,model,criterion)
  
  if val_loss<best_loss:
    best_loss=val_loss
    torch.save(model.state_dict(),'./model.pt') #记录下验证精度
    
# 每个epoch的训练：
def train(train_loader,model,criterion,optimizer,epoch):
  model.train()#切换模型为训练模式
  
  for i,(input,target) in enumerate(train_loader):
    c0,c1,c2,c3,c4,c5=model(data[0])
    loss=criterion(c0,data[1][:,0])+criterion(c1,data[1][:,1])+\
    criterion(c2,data[1][:,2])+criterion(c3,data[1][:,3])+\
    criterion(c4,data[1][:,4])+criterion(c5,data[1][:,5])
    
    loss/=6
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

# 每个epoch的验证：
def validate(val_loader,model,criterion):
  model.eval()
  val_loss=[] #切换为预测模型
  
  #不记录模型梯度信息
  with torch.no_grad():
    for i,(input,target) in enumerate(val_loader):
      c0,c1,c2,c3,c4,c5=model(data[0])
      loss=criterion(c0,data[1][:,0])+criterion(c1,data[1][:,1])+\
      criterion(c2,data[1][:,2])+criterion(c3,data[1][:,3])+\
      criterion(c4,data[1][:,4])+criterion(c5,data[1][:,5])
      
      loss/=6
      val_loss.append(loss.item())
  return np.mean(val_loss)
  
```



## 模型保存与加载

保存和加载模型参数

`torch.save(model_object.state_dict(),'model.pt')`

`model.load_state_dict(torch.load('model.pt'))`



## 调参

深度学习有众多的网络结构和超参数，因此需要反复尝试 ref:http://karpathy.github.io/2019/04/25/recipe/



- 1.初步构建简单的CNN模型，不用特别复杂，跑通训练、验证和预测的流程；
- 2.简单CNN模型的损失会比较大，尝试增加模型复杂度，并观察验证集精度；
- 3.在增加模型复杂度的同时增加数据扩增方法，直至验证集精度不变。

[![IMG](https://github.com/datawhalechina/team-learning/raw/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/IMG/Task04/%E8%B0%83%E5%8F%82%E6%B5%81%E7%A8%8B.png)](https://github.com/datawhalechina/team-learning/blob/master/03 计算机视觉/计算机视觉实践（街景字符编码识别）/IMG/Task04/调参流程.png)



**模型复杂度是相对的，并不一定模型越复杂越好。在有限设备和有限时间下，需要选择能够快速迭代训练的模型。








