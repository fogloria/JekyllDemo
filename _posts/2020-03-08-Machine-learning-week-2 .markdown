---
layout: post
title:  "Machine learning week #2 THR ROC"
date:   2020-03-08 23:55:25 +0800
categories: 
---
# 机器学习Week 2：如何评价模型的好坏

所谓超参数，就是在机器学习算法模型执行之前需要指定的参数。（调参调的就是超参数） 如kNN算法中的k。

与之相对的概念是模型参数，即算法过程中学习的属于这个模型的参数（kNN中没有模型参数，回归算法有很多模型参数）

因为有两个超参数，因此使用双重循环，去查找最合适的两个参数

我们会注意到，`best_estimator_`和`best_score_`参数后面有一个`_`。这是一种常见的语法规范，不是用户传入的参数，而是根据用户传入的规则，自己计算出来的结果，参数名字后面接`_`

网格搜索Grid Serach就是把参数都验证过去

对回归问题的评价：MSE、RMSE、MAE、R方

混淆矩阵(Confusion Matrix)

**精准率（查准率）precision：预测值为1，且预测对了的比例，即：我们关注的那个事件，预测的有多准。**

**召回率（查全率）recall：所有真实值为1的数据中，预测对了的个数，即：我们关注的那个事件真实的发生情况下，我们成功预测的比例是多少。**

视场景兼顾**调和**平均值F1 Score:






thr(阈值要求)始终应该是0.5吗？

分类阈值取不同值，TPR和FPR的计算结果也不同，最理想情况下，我们希望所有正例 & 负例 都被成功预测  TPR=1，FPR=0，即 所有的正例预测值 > 所有的负例预测值，此时阈值取最小正例预测值与最大负例预测值之间的值即可。

关于ROC，x轴是FPR，y轴是TPR，TPR>FPR，即上班平面判断越准确；

在ROC曲线中，曲线下的面积AUC越大，分类效果越好。



-------


简单线性回归衡量标准是看在测试数据集中y的真实值与预测值之间的差距。

### 1.1 均方误差MSE

测试集中的数据量`m`不同，因为有**累加操作**，所以随着数据的增加 ，误差会逐渐积累；因此衡量标准和 `m` 相关。为了抵消掉数据量的形象，可以除去数据量，抵消误差。通过这种处理方式得到的结果叫做 **均方误差MSE（Mean Squared Error）**



### 1.2 均方根误差RMSE

但是使用均方误差MSE收到量纲的影响。例如在衡量房产时，y的单位是（万元），那么衡量标准得到的结果是（万元平方）。为了解决量纲的问题，可以将其开方（为了解决方差的量纲问题，将其开方得到平方差）得到**均方根误差RMSE（Root Mean Squarde Error）**



### 1.3 平均绝对误差MAE

对于线性回归算法还有另外一种非常朴素评测标准。要求真实值 与 预测结果 之间的距离最小，可以直接相减做绝对值，加m次再除以m，即可求出平均距离，被称作**平均绝对误差MAE（Mean Absolute Error）**

在之前确定损失函数时，我们提过，绝对值函数不是处处可导的，因此没有使用绝对值。但是在评价模型时不影响。因此模型的评价方法可以和损失函数不同。



### R Square：

- R^2 <= 1；
- R2越大也好，越大说明减数的分子小，错误率低；当我们预测模型不犯任何错误时，R2最大值1；
- 当我们的模型等于基准模型时，R^2 = 0；
- 如果R^2 < 0，说明我们学习到的模型还不如基准模型。此时，很有可能我们的数据不存在任何线性关系。





