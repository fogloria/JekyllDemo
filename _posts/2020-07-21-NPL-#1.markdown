---
layout: post
title:  "入门NLP - #1 赛题理解"
date:   2020-07-21 20:54:28 +0800
categories: NLP
---
https://tianchi.aliyun.com/competition/entrance/531810/information

### 赛题：新闻文本分类

### 目标：学习NLP的预处理、模型构建、模型训练

### 背景：新闻数据已按**字符级别**匿名处理

处理后的赛题训练数据如下：

| label | text                                                         |
| ----- | ------------------------------------------------------------ |
| 6     | 57 44 66 56 2 3 3 37 5 41 9 57 44 47 45 33 13 63 58 31 17 47 0 1 1 69 26 60 62 15 21 12 49 18 38 20 50 23 57 44 45 33 25 28 47 22 52 35 30 14 24 69 54 7 48 19 11 51 16 43 26 34 53 27 64 8 4 42 36 46 65 69 29 39 15 37 57 44 45 33 69 54 7 25 40 35 30 66 56 47 55 69 61 10 60 42 36 46 65 37 5 41 32 67 6 59 47 0 1 1 68 |

在数据集中标签的对应的关系如下：{'科技': 0, '股票': 1, '体育': 2, '娱乐': 3, '时政': 4, '社会': 5, '教育': 6, '财经': 7, '家居': 8, '游戏': 9, '房产': 10, '时尚': 11, '彩票': 12, '星座': 13}

这是个以自然语言处理为背景的字符识别问题。

数据：训练集20w，测试集5W

### 评测指标：类别f1_score的均值

F1 = 2 * (precision * recall) / (precision + recall)

'micro':（TP/FN/FP）
Calculate metrics globally by counting the total true positives, false negatives and false positives.

'macro':（不考虑标签不平衡）
Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.

'weighted'（加权计算）:
Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.

看了下后面的内容，这题用了 average='macro'


### 解题思路：

赛题思路分析：赛题本质是一个文本分类问题，需要根据每句的字符进行分类。但赛题给出的数据是匿名化的，不能直接使用中文分词等操作，这个是赛题的难点。

因此本次赛题的难点是需要对匿名字符进行建模，进而完成文本分类的过程。由于文本数据是一种典型的非结构化数据，因此可能涉及到`特征提取`和`分类模型`两个部分。为了减低参赛难度，我们提供了一些解题思路供大家参考：

- 思路1：TF-IDF + 机器学习分类器

直接使用TF-IDF对文本提取特征，并使用分类器进行分类。在分类器的选择上，可以使用SVM、LR、或者XGBoost。

- 思路2：FastText

FastText是入门款的词向量，利用Facebook提供的FastText工具，可以快速构建出分类器。

- 思路3：WordVec + 深度学习分类器

WordVec是进阶款的词向量，并通过构建深度学习分类完成分类。深度学习分类的网络结构可以选择TextCNN、TextRNN或者BiLSTM。

- 思路4：Bert词向量

Bert是高配款的词向量，具有强大的建模学习能力。


### 其他…数据清洗（参考他人笔记）
特殊符号 清除
标点 清除
大小写 统一
Stemming（词根化） or Lemmatization（词形还原）
停用词 清除

### next…分析数据
可以从两方面探索数据集：
1）分类是否均衡，如果不均衡可能要考虑采用过采样或欠采样的预处理方法
2）文本长度的分布情况，对于不同标签，文本长度是否具有显著差异，这会影响到NLP模型的使用以及特征构造





