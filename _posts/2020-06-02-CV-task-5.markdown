---
layout: post
title:  "入门CV - task5 模型集成"
date:   2020-06-02 17:16:03 +0800
categories: CV
---
## 集成学习方法

与验证集划分联系紧密，常见方法有Stacking，Bagging，Boosting

如10折交叉验证，A：对预测的结果的概率进行平均，解码为字符；B：对预测字符投票。

具体的集成学习方法需要与验证集划分方法结合，Dropout和TTA在所有场景起作用。



## DL中的集成

#### Dropout：在每个train batch中，随机让部分节点停止工作，而在test set中让所有节点都起作用。

```python
class SVHN_Model1(nn.Module):
  def __init__(self):
    super(SVHN_Model1,self).__init__()
    self.cnn=nn.Sequential(
      nn.Conv2d(3,16,kernal_size=(3,3),stride=(2,2)),
      nn.ReLU(),
      nn.Dropout(0.25),
      nn.MaxPool2d(2),
      nn.Conv2d(16,32,kernal_size=(3,3),stride(2,2)),
      nn.ReLU(),
      nn.Dropout(0.25),
      nn.MaxPool2d(2),
    )
    
    self.fc1=nn.Linear(32*3*7,11)
    self.fc2=nn.Linear(32*3*7,11)
    self.fc3=nn.Linear(32*3*7,11)
    self.fc4=nn.Linear(32*3*7,11)
    self.fc5=nn.Linear(32*3*7,11)
    self.fc6=nn.Linear(32*3*7,11)
    
  def forward(self,img):
    feat=self.cnn(img)
    feat=feat.view(feat.shape[0],-1)
    c1=self.fc1(feat)
    c2=self.fc2(feat)
    c3=self.fc3(feat)
    c4=self.fc4(feat)
    c5=self.fc5(feat)
    c6=self.fc6(feat)
    return c1,c2,c3,c4,c5,c6
```



#### TTA：Test Time Augmentation 测试集数据扩增，对同一样本预测三次，对三次结果进行平均。

```python
def predict(test_loader,model,tta=10):
  model.eval()
  test_pred_tta=None
  for _ in range(tta):
    test_pred=[]
    
    with torch.no_grad():
      for i,(input,target) in enumerate(test_loader):
        c0,c1,c2,c3,c4,c5=model(data[0])
        output=np.concatenate([c0.data.numpy(),
								c1.data.numpy(),c2.data.numpy(),
								c3.data.numpy(),c4.data.numpy(),
								c5.data.numpy()],axis=1)
        test_pred.append(output)
        
    test_pred=np.vstack(test_pred)
    if test_pred_tta is None:
      test_pred_tta=test_pred
    else:
      test_pred_tta+=test_pred
      
  return test_pred_tta        
```



#### Snapshot：只训练了一个CNN模型，使用cyclical learning rate进行训练模型，并保存精度比较好的一些checkopint，最后将多个checkpoint进行模型集成。

[![IMG](https://github.com/datawhalechina/team-learning/raw/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/IMG/Task05/Snapshot.png)](https://github.com/datawhalechina/team-learning/blob/master/03 计算机视觉/计算机视觉实践（街景字符编码识别）/IMG/Task05/Snapshot.png)

由于在cyclical learning rate中学习率的变化有周期性变大和减少的行为，因此CNN模型很有可能在跳出局部最优进入另一个局部最优。在Snapshot论文中作者通过使用表明，此种方法可以在一定程度上提高模型精度，但需要更长的训练时间。








